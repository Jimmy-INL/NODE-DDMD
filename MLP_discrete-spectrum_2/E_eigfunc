E_recon 0.0027261026091578633
E_recon 0.0034746352108080128
E_recon 0.002881956860347077
E_recon 0.002139007701712855
E_recon 0.0010062626375764525
E_recon 0.002432451671416637
E_recon 0.002939829574013885
E_recon 0.0044607129659974916
E_recon 0.0011414510325900259
E_recon 0.0024927347730491593

E_eigfunc 0.04795504415965313
E_eigfunc 0.022396760965857746
E_eigfunc 0.05851993946350781
E_eigfunc 0.021912752153203575
E_eigfunc 0.010761504318196802
E_eigfunc 0.006744968389663307
E_eigfunc 0.006144558238278986
E_eigfunc 0.005541948167590628
E_eigfunc 0.004470278084861669
E_eigfunc 0.0031041126588882213
E_eigfunc 0.0041001886639610964
E_eigfunc 0.003104827849436584
E_eigfunc 0.003894606880015155
E_eigfunc 0.002500929356446611
E_eigfunc 0.005358367981915146
E_eigfunc 0.0063526300397107275
E_eigfunc 0.0011907977801958664
E_eigfunc 0.0033313825078942778
E_eigfunc 0.0015769416564299238
E_eigfunc 0.0028420050381450694
E_eigfunc 0.0028420050381450694
E_eigfunc 0.000774979477514359
E_eigfunc 0.000774979477514359
E_eigfunc 0.017293638833886075
E_eigfunc 0.015631564563501284


2941 steps
loss tensor(17.9708, grad_fn=<AddBackward0>)
[ 0.99962205+0.j         0.9969698 +0.j         0.99653816+0.j
  0.99989265+0.j         0.98752236+0.j         0.9149843 +0.j
  0.77176845+0.j         0.7858218 +0.j         0.804849  +0.j
  0.8324146 +0.j         0.7019487 +0.j         0.70808566+0.j
  0.5759448 +0.j         0.59763306+0.j         0.27222326+0.j
  0.30682194+0.j         0.5810548 +0.j         0.57708013+0.j
  0.6495994 +0.j        -0.09059174+0.5832901j -0.09059174-0.5832901j
 -0.02361503-0.3666114j -0.02361503+0.3666114j  0.05788035+0.j
  0.05538541+0.j       ]